apiVersion: apps/v1
kind: Deployment
metadata:
  name: ray-worker
  namespace: mochi-video-gen
  labels:
    app.kubernetes.io/name: ray-worker
    app.kubernetes.io/instance: mochi-ray-worker
    app.kubernetes.io/part-of: mochi-video-gen
spec:
  replicas: 2  # Start with 2 replicas as requested
  selector:
    matchLabels:
      app.kubernetes.io/name: ray-worker
      app.kubernetes.io/instance: mochi-ray-worker
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ray-worker
        app.kubernetes.io/instance: mochi-ray-worker
    spec:
      serviceAccountName: mochi-service-account
      containers:
      - name: ray-worker
        image: glususer/mochi-ray:latest
        env:
        - name: RAY_DISABLE_DOCKER_CPU_WARNING
          value: "1"
        - name: RAY_OBJECT_STORE_ALLOW_SLOW_STORAGE
          value: "1"
        - name: NVIDIA_VISIBLE_DEVICES
          value: "all"
        - name: NVIDIA_DRIVER_CAPABILITIES
          value: "compute,utility"
        - name: REDIS_HOST
          value: "redis-service"
        - name: REDIS_PORT
          value: "6379"
        - name: REDIS_DB
          value: "0"
        envFrom:
        - configMapRef:
            name: mochi-config
        resources:
          requests:
            cpu: 6
            memory: 32Gi
            nvidia.com/gpu: 2  # Request 2 GPUs per replica
          limits:
            cpu: 8
            memory: 64Gi
            nvidia.com/gpu: 2  # Limit to 2 GPUs per replica
        volumeMounts:
        - name: ray-tmp
          mountPath: /raytmp
        - name: data-volume
          mountPath: /data
        - name: cache-volume
          mountPath: /cache
        - name: models-volume
          mountPath: /models
        - name: shm
          mountPath: /dev/shm
        command:
        - /bin/bash
        - -c
        - |
          ray start \
            --address=ray-head-service:6380 \
            --num-cpus=8 \
            --num-gpus=2 \
            --temp-dir=/raytmp \
            --object-store-memory=30000000000 \
            --block
        livenessProbe:
          exec:
            command:
            - /bin/bash
            - -c
            - "ps aux | grep 'ray start' | grep -v grep"
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 5
        readinessProbe:
          exec:
            command:
            - /bin/bash
            - -c
            - "ps aux | grep 'ray start' | grep -v grep"
          initialDelaySeconds: 30
          periodSeconds: 15
          timeoutSeconds: 5
          failureThreshold: 5
        lifecycle:
          preStop:
            exec:
              command:
              - ray
              - stop
      volumes:
      - name: ray-tmp
        emptyDir:
          sizeLimit: 20Gi
      - name: data-volume
        persistentVolumeClaim:
          claimName: videos-pvc
      - name: cache-volume
        persistentVolumeClaim:
          claimName: cache-pvc
      - name: models-volume
        persistentVolumeClaim:
          claimName: models-pvc
      - name: shm
        emptyDir:
          medium: Memory
          sizeLimit: 10Gi
      # Node selection and GPU constraints
      nodeSelector:
        kubernetes.io/os: linux
        accelerator: nvidia-gpu  # Ensure GPU nodes
      affinity:
        # Spread workers across different nodes for fault tolerance
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app.kubernetes.io/name
                  operator: In
                  values:
                  - ray-worker
              topologyKey: kubernetes.io/hostname
        # Prefer GPU-enabled nodes
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: accelerator
                operator: In
                values:
                - nvidia-gpu
      tolerations:
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
      - key: "ray.io/node-type"
        operator: "Equal"
        value: "worker"
        effect: "NoSchedule"